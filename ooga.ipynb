{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDate(html):\n",
    "    date = html.find(class_=\"date_read_value\")\n",
    "    if date is not None:\n",
    "        date = date.get_text()\n",
    "        try:\n",
    "            format = '%b %d, %Y'\n",
    "            dateStr = dt.strptime(date, format)\n",
    "        except (ValueError):\n",
    "            try:\n",
    "                format = '%b %Y'\n",
    "                dateStr = dt.strptime(date, format)\n",
    "            except():\n",
    "                return dt.today()\n",
    "        return dateStr\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def getId(html):\n",
    "    titleTd = html.find(class_=\"title\")\n",
    "    linkText = titleTd.find(\"a\").get('href').split('/')[3]\n",
    "    splitLink = linkText.split('-')\n",
    "    if splitLink.__len__() == 1:\n",
    "        splitLink = linkText.split('.')\n",
    "    if splitLink.__len__() > 0:\n",
    "        return splitLink[0]\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def getTitle(html):\n",
    "    title = html.find(class_=\"Text__title1\")\n",
    "    return title.get_text() if title is not None else \"n/a\"\n",
    "\n",
    "def getAuthor(html):\n",
    "    author = html.find(class_=\"ContributorLink__name\")\n",
    "    return author.get_text() if author is not None else \"n/a\"\n",
    "\n",
    "def getGivenRating(html):\n",
    "    rating = html.find(class_=\"staticStars\").get(\"title\")\n",
    "    match rating:\n",
    "        case 'did not like it':\n",
    "            return 1\n",
    "        case 'it was ok':\n",
    "            return 2\n",
    "        case 'liked it':\n",
    "            return 3\n",
    "        case 'really liked it':\n",
    "            return 4\n",
    "        case 'it was amazing':\n",
    "            return 5\n",
    "        case default:\n",
    "            return np.NaN\n",
    "\n",
    "def getAvgRating(html):\n",
    "    rating = html.find(class_=\"RatingStatistics__rating\")\n",
    "    return rating.get_text()\n",
    "\n",
    "def getGenres(html):\n",
    "    genresListContainer = html.find(class_=\"BookPageMetadataSection__genres\")\n",
    "    genresHtml = genresListContainer.find_all(class_=\"Button__labelItem\")\n",
    "    genres = map(lambda obj: obj.get_text(), genresHtml)\n",
    "    return list(genres)[slice(5)] # just get top 5 genres\n",
    "\n",
    "def getInfo(html):\n",
    "    bookDetails = html.find(class_=\"BookDetails\")\n",
    "    pagesHtml = bookDetails.find(\"p\", {\"data-testid\" : \"pagesFormat\"})\n",
    "    pages = pagesHtml.get_text().split()[0]\n",
    "    pubInfo = bookDetails.find(\"p\", {\"data-testid\" : \"publicationInfo\"})\n",
    "    date = pubInfo.get_text().split()[-1]\n",
    "    return pages, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'Access-Control-Allow-Origin': '*',\n",
    "    'Access-Control-Allow-Methods': 'GET',\n",
    "    'Access-Control-Allow-Headers': 'Content-Type',\n",
    "    'Access-Control-Max-Age': '3600',\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2023\n",
    "minDate = dt(year, 1, 1)\n",
    "maxDate = dt(year + 1, 1, 1)\n",
    "\n",
    "# TODO: add in maxDate checking\n",
    "# uid = 105241766\n",
    "uid = 153462289\n",
    "page = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "isFirstPage = False\n",
    "while not isFirstPage:\n",
    "    url = f'https://www.goodreads.com/review/list/{uid}?page={page}ref=nav_mybooks&shelf=read&sort=date_read'\n",
    "    req = requests.get(url, headers)\n",
    "    soup = BeautifulSoup(req.content, 'html.parser')\n",
    "    pageBooks = soup.find_all(class_=\"bookalike\")\n",
    "\n",
    "    # TODO: figure out if this should be < or <=\n",
    "    pageContainsMaxDate = [book for book in pageBooks if getDate(book) is not None and getDate(book) <= maxDate].__len__() > 0\n",
    "    if pageContainsMaxDate:\n",
    "        isFirstPage = True\n",
    "    else:\n",
    "        page += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting reading info...\n",
      "29 books found for 2023\n"
     ]
    }
   ],
   "source": [
    "print('Getting reading info...')\n",
    "isLastPage = False\n",
    "bookIds = []\n",
    "bookDatesRead = []\n",
    "bookGivenRatings = []\n",
    "while not isLastPage:\n",
    "    url = f'https://www.goodreads.com/review/list/{uid}?page={page}ref=nav_mybooks&shelf=read&sort=date_read'\n",
    "\n",
    "    req = requests.get(url, headers)\n",
    "    soup = BeautifulSoup(req.content, 'html.parser')\n",
    "    pageBooks = soup.find_all(class_=\"bookalike\")\n",
    "\n",
    "    # check for completed books\n",
    "    pageContainsMinDate = [book for book in pageBooks if getDate(book) is not None and getDate(book) < minDate].__len__() > 0\n",
    "    if pageContainsMinDate:\n",
    "        isLastPage = True\n",
    "    \n",
    "    # filter based on \n",
    "    pageBooks = [book for book in pageBooks if getDate(book) is not None and getDate(book) >= minDate and getDate(book) < maxDate]\n",
    "    for book in pageBooks:\n",
    "        bookIds.append(getId(book))\n",
    "        bookDatesRead.append(getDate(book))\n",
    "        bookGivenRatings.append(getGivenRating(book))\n",
    "        # TODO: add null checking to all of these\n",
    "\n",
    "    page += 1\n",
    "\n",
    "print(f'{len(bookIds)} books found for {year}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting info for each book...\n",
      "\n",
      "something went wrong :(\n",
      "178930867\n",
      "https://goodreads.com/book/show/178930867\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Getting info for each book...')\n",
    "bookTitles = []\n",
    "bookAuthors = []\n",
    "bookAvgRatings = []\n",
    "bookGenres = []\n",
    "bookNumPages = []\n",
    "bookPubYears = []\n",
    "for id in bookIds:\n",
    "    url = f'https://goodreads.com/book/show/{id}'\n",
    "    req = requests.get(url, headers)\n",
    "    soup = BeautifulSoup(req.content, 'html.parser')\n",
    "    bookContent = soup.find(class_=\"BookPage__mainContent\")\n",
    "    if bookContent is None:\n",
    "        print('\\nsomething went wrong :(')\n",
    "        print(id)\n",
    "        print(url)\n",
    "        print('\\n')\n",
    "        bookTitles.append(\"n/a\")\n",
    "        bookAuthors.append(\"n/a\")\n",
    "        bookAvgRatings.append(np.NaN)\n",
    "        bookGenres.append(np.NaN)\n",
    "        numPages, pubYear = np.NaN,np.NaN\n",
    "        bookNumPages.append(np.NaN)\n",
    "        bookPubYears.append(np.NaN)\n",
    "        # print(soup.prettify())\n",
    "        continue\n",
    "    bookTitles.append(getTitle(bookContent))\n",
    "    bookAuthors.append(getAuthor(bookContent))\n",
    "    bookAvgRatings.append(getAvgRating(bookContent))\n",
    "    bookGenres.append(getGenres(bookContent))\n",
    "    numPages, pubYear = getInfo(bookContent)\n",
    "    bookNumPages.append(int(numPages))\n",
    "    bookPubYears.append(int(pubYear))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookData = pd.DataFrame()\n",
    "bookData['ID'] = bookIds\n",
    "bookData['Titles'] = bookTitles\n",
    "bookData['Author'] = bookAuthors\n",
    "bookData['Date Read'] = bookDatesRead\n",
    "bookData['User Rating'] = bookGivenRatings\n",
    "bookData['Average Rating'] = bookAvgRatings\n",
    "bookData['Genres'] = bookGenres\n",
    "bookData['Number of Pages'] = bookNumPages\n",
    "bookData['Year Published'] = bookPubYears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max pages: 804\n",
      "Min pages: 194\n",
      "Avg pages: 442\n",
      "\n",
      "\n",
      "Most common author: [('Sarah J. Maas', 9), ('Holly Black', 3), ('Catherine  Walsh', 2)]\n",
      "\n",
      "\n",
      "Top 5 genres: [('Romance', 25), ('Fantasy', 21), ('Fiction', 18), ('Young Adult', 15), ('Contemporary', 7)]\n",
      "\n",
      "\n",
      "This year, you tended to rate books higher than the average Goodreads user. (4.45 : 4.07)\n"
     ]
    }
   ],
   "source": [
    "pagesData = bookData[\"Number of Pages\"].dropna()\n",
    "print(f'Max pages: {int(pagesData.max())}')\n",
    "print(f'Min pages: {int(pagesData.min())}')\n",
    "print(f'Avg pages: {round(pagesData.mean())}')\n",
    "print('\\n')\n",
    "\n",
    "mostCommonAuthor = Counter(bookData['Author']).most_common(3)\n",
    "print(f'Most common author: {mostCommonAuthor}')\n",
    "print('\\n')\n",
    "\n",
    "allGenresList = []\n",
    "for genreList in bookData['Genres'].dropna():\n",
    "    allGenresList.extend(genreList)\n",
    "topGenres = Counter(allGenresList).most_common(5)\n",
    "print(f'Top 5 genres: {topGenres}')\n",
    "print('\\n')\n",
    "\n",
    "roundedAvgRatings = list(map(lambda num: round(float(num)), bookData['Average Rating'].dropna()))\n",
    "avgMean = np.mean(roundedAvgRatings)\n",
    "userMean = bookData['User Rating'].dropna().mean()\n",
    "if userMean < avgMean:\n",
    "    print(f'This year, you tended to rate books lower than the average Goodreads user. ({round(userMean, 2)} : {round(avgMean, 2)})')\n",
    "elif userMean > avgMean:\n",
    "    print(f'This year, you tended to rate books higher than the average Goodreads user. ({round(userMean, 2)} : {round(avgMean, 2)})')\n",
    "else:\n",
    "    print(f'This year, you tended to rate books the same as the average Goodreads user.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
